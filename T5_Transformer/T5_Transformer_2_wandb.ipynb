{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformers_summarization_wandb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mSW9hbeyPhc",
        "outputId": "9a829301-9dfe-400f-9bc6-2128a6a167bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5lgzMTYyX7-",
        "outputId": "ca67b59a-1dbe-4450-e194-dc3ebdac6f4a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkPXMpuH5aoR",
        "outputId": "f3b69222-9048-4940-ef99-d87aa77c68f0"
      },
      "source": [
        "!pip install T5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: T5 in /usr/local/lib/python3.7/dist-packages (0.9.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from T5) (1.0.1)\n",
            "Requirement already satisfied: six>=1.14 in /usr/local/lib/python3.7/dist-packages (from T5) (1.15.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from T5) (0.1.96)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (from T5) (0.0.4)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from T5) (0.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from T5) (1.10.0+cu111)\n",
            "Requirement already satisfied: tfds-nightly in /usr/local/lib/python3.7/dist-packages (from T5) (4.4.0.dev202111300106)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from T5) (1.1.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from T5) (0.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from T5) (1.19.5)\n",
            "Requirement already satisfied: seqio in /usr/local/lib/python3.7/dist-packages (from T5) (0.0.7)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from T5) (2.9.1)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from T5) (2.0.0)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from T5) (0.5.3)\n",
            "Requirement already satisfied: mesh-tensorflow[transformer]>=0.1.13 in /usr/local/lib/python3.7/dist-packages (from T5) (0.1.19)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from T5) (3.2.5)\n",
            "Requirement already satisfied: transformers>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from T5) (4.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from T5) (1.4.1)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.7/dist-packages (from T5) (2.7.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->T5) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->T5) (4.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->T5) (21.3)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->T5) (0.9.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->T5) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->T5) (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->T5) (0.0.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->T5) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->T5) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->T5) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=2.7.0->T5) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->T5) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->T5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->T5) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->T5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->T5) (3.0.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->T5) (0.4.4)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu->T5) (2.3.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->T5) (0.8.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.7.0->T5) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.7.0->T5) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->T5) (3.0.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->T5) (1.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->T5) (0.3.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->T5) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->T5) (3.17.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->T5) (5.4.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->T5) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->T5) (0.1.6)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->T5) (21.2.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->T5) (3.6.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->T5) (1.53.0)\n",
            "Requirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->T5) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->T5) (0.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (0.37.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (1.13.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (2.7.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (0.22.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (12.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (3.10.0.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (1.42.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (1.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->T5) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em9ZfOtNeioF"
      },
      "source": [
        "!pip install transformers -q\n",
        "!pip install wandb -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVJho3tRGZN2",
        "outputId": "a22f624e-ab97-4a8c-a07e-e18384087126"
      },
      "source": [
        "! pip install transformers==4.1.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.1.1 in /usr/local/lib/python3.7/dist-packages (4.1.1)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (0.9.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (0.0.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (3.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.1.1) (3.0.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xejI63bFes1-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5rnZ-rOfUxD",
        "outputId": "71431dff-14f4-43b8-cc85-39a9b4bbaad4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec  1 03:21:36 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    28W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lDusDR5ffR1"
      },
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRWf0VM_ftDh",
        "outputId": "594afe50-41d2-43e4-9026-a6f9d0374eae"
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkkon\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beMokDAfwcVI"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = summ_len\n",
        "        self.text = self.data.text\n",
        "        self.ctext = self.data.ctext\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ctext = str(self.ctext[index])\n",
        "        ctext = ' '.join(ctext.split())\n",
        "\n",
        "        text = str(self.text[index])\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
        "        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
        "\n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "        target_ids = target['input_ids'].squeeze()\n",
        "        target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'source_ids': source_ids.to(dtype=torch.long), \n",
        "            'source_mask': source_mask.to(dtype=torch.long), \n",
        "            'target_ids': target_ids.to(dtype=torch.long),\n",
        "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y7EVCQhkvlK"
      },
      "source": [
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "    model.train()\n",
        "    for _,data in enumerate(loader, 0):\n",
        "        y = data['target_ids'].to(device, dtype = torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        lm_labels = y[:, 1:].clone().detach()\n",
        "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        if _%10 == 0:\n",
        "            wandb.log({\"Training Loss\": loss.item()})\n",
        "\n",
        "        if _%500==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50YMzPcmmiTH"
      },
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            y = data['target_ids'].to(device, dtype = torch.long)\n",
        "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids = ids,\n",
        "                attention_mask = mask, \n",
        "                max_length=150, \n",
        "                num_beams=4,\n",
        "                repetition_penalty=2.5, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True\n",
        "                )\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "            if _%100==0:\n",
        "                print(f'Completed {_}')\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "    return predictions, actuals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lesitrtR3C7r"
      },
      "source": [
        "def test(tokenizer, model, device, loader):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for _, data in enumerate(loader, 0):\n",
        "        tokenized_text = tokenizer(input_text, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "        ids = tokenized_text['input_ids'].to(device, dtype = torch.long)\n",
        "        mask = tokenized_text['attention_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "        generated_ids = model.generate(\n",
        "            input_ids = ids,\n",
        "            attention_mask = mask, \n",
        "            max_length=500, \n",
        "            num_beams=4,\n",
        "            repetition_penalty=2.5, \n",
        "            length_penalty=1.0, \n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        pred = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "\n",
        "    print(\"\\noutput:\\n\" + pred[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "Ozl2i1tSpyq5",
        "outputId": "ce053bf6-7c8c-42fe-a7f7-8fd989a62d37"
      },
      "source": [
        "def main(input_text):\n",
        "    # WandB – Initialize a new run\n",
        "    wandb.init(project=\"transformers_tutorials_summarization\")\n",
        "\n",
        "    # WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "    # Defining some key variables that will be used later on in the training  \n",
        "    config = wandb.config          # Initialize config\n",
        "    config.TRAIN_BATCH_SIZE = 2    # input batch size for training (default: 64)\n",
        "    config.VALID_BATCH_SIZE = 2    # input batch size for testing (default: 1000)\n",
        "    config.TEST_BATCH_SIZE = 2\n",
        "    config.TRAIN_EPOCHS = 2        # number of epochs to train (default: 10)\n",
        "    config.VAL_EPOCHS = 1 \n",
        "    config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
        "    config.SEED = 42               # random seed (default: 42)\n",
        "    config.MAX_LEN = 512\n",
        "    config.SUMMARY_LEN = 500\n",
        "\n",
        "    # Set random seeds and deterministic pytorch for reproducibility\n",
        "    torch.manual_seed(config.SEED) # pytorch random seed\n",
        "    np.random.seed(config.SEED) # numpy random seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    # tokenzier for encoding the text\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "    \n",
        "\n",
        "    # Importing and Pre-Processing the domain data\n",
        "    # Selecting the needed columns only. \n",
        "    # Adding the summarzie text in front of the text. This is to format the dataset similar to how T5 model was trained for summarization task. \n",
        "    df = pd.read_csv('/content/drive/MyDrive/news_summary.csv', encoding='latin-1')\n",
        "    df = df[['text','ctext']]\n",
        "    df.ctext = 'summarize: ' + df.ctext\n",
        "    print(df.head())\n",
        "\n",
        "    \n",
        "    # Creation of Dataset and Dataloader\n",
        "    # Defining the train size. So 80% of the data will be used for training and the rest will be used for validation. \n",
        "    train_size = 0.8\n",
        "    train_dataset = df.sample(frac=train_size,random_state = config.SEED)\n",
        "    val_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
        "    train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "    test_dataset = pd.DataFrame({'text': [''], 'ctext':[input_text]})\n",
        "\n",
        "    print(\"FULL Dataset: {}\".format(df.shape))\n",
        "    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "    print(\"TEST Dataset: {}\".format(val_dataset.shape))\n",
        "\n",
        "\n",
        "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
        "    training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "    val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "    test_set = CustomDataset(test_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "\n",
        "    # Defining the parameters for creation of dataloaders\n",
        "    train_params = {\n",
        "        'batch_size': config.TRAIN_BATCH_SIZE,\n",
        "        'shuffle': True,\n",
        "        'num_workers': 0\n",
        "        }\n",
        "\n",
        "    val_params = {\n",
        "        'batch_size': config.VALID_BATCH_SIZE,\n",
        "        'shuffle': False,\n",
        "        'num_workers': 0\n",
        "        }\n",
        "\n",
        "    test_params = {\n",
        "        'batch_size': config.TEST_BATCH_SIZE,\n",
        "        'shuffle': False,\n",
        "        'num_workers': 0\n",
        "        }\n",
        "\n",
        "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "    training_loader = DataLoader(training_set, **train_params)\n",
        "    val_loader = DataLoader(val_set, **val_params)\n",
        "    testing_loader = DataLoader(test_set, **test_params)\n",
        "\n",
        "\n",
        "    \n",
        "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "    # Log metrics with wandb\n",
        "    wandb.watch(model, log=\"all\")\n",
        "    # Training loop\n",
        "    print('Initiating Fine-Tuning for the model on our dataset')\n",
        "\n",
        "    for epoch in range(config.TRAIN_EPOCHS):\n",
        "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
        "\n",
        "\n",
        "    # Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
        "    # Saving the dataframe as predictions.csv\n",
        "    print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
        "    for epoch in range(config.VAL_EPOCHS):\n",
        "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
        "        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "        final_df.to_csv('/content/drive/MyDrive/predictions.csv')\n",
        "        print('Output Files generated for review')\n",
        "\n",
        "    pred = test(tokenizer, model, device, val_loader)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"input:\")\n",
        "    input_text = input()\n",
        "    main(input_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:\n",
            "So you have to run k-means algorithm again, and again, then until you find the optimal result, why we it requires initial means, and it matters what you pick for initial means, for example, this centers are initialized like this, these data points. Okay, and actually, using another similar to measure means the these 2D input space. So you can see this input image is broken in two places and each class form or process, actually, similar reasons. But if you don't use equally their distance, instead, you use another way to define a similarity between vectors, you will have different clustering result. So it forms a cluster 1 and this Center is close to these oranges, of course, and these data points, make a cluster 2 and in the same way, we make a cluster 3 and close to 40 K. So, this green point is more close to this data point rather than this data point. But let's say you have different initial means. And then next small step of iteration is change the cluster Center to the average of its assigned, right point. So here is a picture example, each Square corresponds to each object, or data sample, or data point, and you can see the this yellow group are grouped together since they are more similar to each other. Well, you can take another way if we just faced by these data points with two classes. So again, like, in the previous example, If you have this kind of result on this result will not change order. We'll have a better result if this cluster one is formed here because zero is from the here. And the third limitation is the k-means cannot be able to properly cluster in some cases like this. If our algorithm will not stop on this local minimum, you can change this on purpose, enter into here and change this blue blue circle to here. So the initial Center of five classes were here, but we have the new, assigns data point like this wall, like this. This K means clustering but I'm sure this one is quite busy. So we are just going to cross through these data points into K classes and then we iterate, these small steps later. We have only read the data and the final one was refers to learning, but I will talk about it later on in this course. Is the task of grouping, of several of object, or we can say, or set of data samples data points, in a way that the same group are more similar to each other. We will have different clustering results like this and in the previous slide, we said the similar data points are grouped together, but these similar is not a scientific term. And again, let's see the image segmentation result using K means clustering.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkkon\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/kkon/transformers_tutorials_summarization/runs/13ur63ql\" target=\"_blank\">denim-valley-49</a></strong> to <a href=\"https://wandb.ai/kkon/transformers_tutorials_summarization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text                                              ctext\n",
            "0  The Administration of Union Territory Daman an...  summarize: The Daman and Diu administration on...\n",
            "1  Malaika Arora slammed an Instagram user who tr...  summarize: From her special numbers to TV?appe...\n",
            "2  The Indira Gandhi Institute of Medical Science...  summarize: The Indira Gandhi Institute of Medi...\n",
            "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  summarize: Lashkar-e-Taiba's Kashmir commander...\n",
            "4  Hotels in Maharashtra will train their staff t...  summarize: Hotels in Mumbai and other Indian c...\n",
            "FULL Dataset: (4514, 2)\n",
            "TRAIN Dataset: (3611, 2)\n",
            "TEST Dataset: (903, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
            "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating Fine-Tuning for the model on our dataset\n",
            "Epoch: 0, Loss:  6.237545490264893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss:  2.215460777282715\n",
            "Epoch: 0, Loss:  2.6175198554992676\n",
            "Epoch: 0, Loss:  1.394105076789856\n",
            "Epoch: 1, Loss:  2.008376359939575\n",
            "Epoch: 1, Loss:  1.1268078088760376\n",
            "Epoch: 1, Loss:  1.7109566926956177\n",
            "Epoch: 1, Loss:  1.443698763847351\n",
            "Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1065: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  next_indices = next_tokens // vocab_size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 0\n",
            "Completed 100\n",
            "Completed 200\n",
            "Completed 300\n",
            "Completed 400\n",
            "Output Files generated for review\n",
            "\n",
            "output:\n",
            "this data points, make a cluster 1 and in the same way, make a cluster 3 and close to 40 K. So, the initial Center of five classes were here, but we have the new, assigns data point like this wall, like this. This means clustering but I'm sure this one is quite busy. The next small step of iteration is change the cluster Center to the average of its assigned, right point.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgfu0oPSFKzL"
      },
      "source": [
        "Almost as abruptly as she had vanished, Chinese tennis star Peng Shuai reappeared in public view over the weekend.\n",
        "\n",
        "Since Friday evening, a steady stream of photos and videos purporting to show a smiling Peng going about her life in Beijing have surfaced on Twitter -- all posted by individuals working for Chinese government-controlled media and the state sport system, on a platform blocked in China.\n",
        "The apparent propaganda push was followed Sunday by a video call between Peng and International Olympic Committee (IOC) president Thomas Bach, during which the three-time Olympian insisted she is \"safe and well, living at her home in Beijing\" and \"would like to have her privacy respected,\" according to a statement from the IOC.\n",
        "The flurry of \"proof of life\" videos came amid a firestorm of global concern for Peng, who disappeared from the public eye for more than two weeks after taking to social media to accuse former Vice Premier Zhang Gaoli of coercing her into sex at his home -- an explosive and politically sensitive allegation that triggered blanket censorship in China.\n",
        "While Peng's public reappearances may allay some of the worst fears about her immediate safety and well-being, they have failed to quell broader concerns about her freedoms and growing calls for a full investigation into her sexual assault allegations.\n",
        "\"It was good to see Peng Shuai in recent videos, but they don't alleviate or address the WTA's concern about her well-being and ability to communicate without censorship or coercion,\" a spokesperson for the Women's Tennis Association (WTA) told CNN in a statement, following Peng's call with the IOC.\n",
        "\n",
        "Human rights advocates who have long followed Beijing's silencing campaigns are also unconvinced.\n",
        "\"What we have here is essentially a state-controlled narrative: only the government and its affiliated media are generating and distributing the content about Peng's story,\" said Maya Wang, senior China researcher at Human Rights Watch (HRW).\n",
        "\"While it is possible that Peng is well, the history of the Chinese government disappearing people and then making videos of them to prove that they are unharmed when it is, in fact, the opposite, should make us worried about Peng's safety,\" she added.\n",
        "The video clips appear to be specifically -- yet crudely -- crafted to show that Peng is \"free\" and living a \"normal\" life.\n",
        "In footage released on Saturday, Peng was seen out to dinner with several people state media journalists have described as \"her coach and friends.\" The clips made repeated, deliberate references to the dates, while Peng kept nodding to the man speaking next to her, not saying anything.\n",
        "None of the videos made even the vaguest mention of Peng's sexual assault allegations against Zhang. Instead, they focused on her smiles and apparent good-spirits -- which state media propagandists were eager to highlight.\n",
        "\n",
        "\"Can any girl fake such sunny smile under pressure?\" asked Hu Xijin, the editor-in-chief of state-run tabloid the Global Times, in a tweet Sunday, accompanying a clip of a smiley Peng signing larged-sized tennis balls for children at a junior tennis match in Beijing.\n",
        "\"Those who suspect Peng Shuai is under duress, how dark they must be inside. There must be many, many forced political performances in their countries,\" Hu wrote on Twitter.\n",
        "The Global Times, like other government-controlled media outlets in China, has made no reference to Peng's apparent disappearance, nor her allegations against Zhang. Hu has also been careful on Twitter not to mention the reason why Peng is in the spotlight, referring to it only obliquely as \"the thing people talked about.\"\n",
        "Chinese authorities have not acknowledged Peng's allegations against Zhang, and there is no indication an investigation is underway. It remains unclear if Peng has reported her allegations to the police.\n",
        "Speaking at a news conference Monday, Chinese Foreign Ministry spokesperson Zhao Lijian reiterated that Peng's accusation is not a diplomatic issue and declined to comment further.\n",
        "Zhang has kept a low profile and faded from public life since his retirement in 2018, and there is no public information relating to his current whereabouts.\n",
        "Skepticism as to Peng's well-being especially runs high among Chinese activists who have observed from a close range how the government has silenced and coerced their peers.\n",
        "\"The reality is, they have huge control over Peng Shuai -- to the extent that it's enough to make her cooperate and become an actor,\" alleged Lv Pin, a prominent Chinese feminist now based in New York.\n",
        "\"This has happened in plenty of cases in the past. Many 'criminals' who were forced to confess on television had to make their performances look real,\" she said, referring to a series of forced confessions aired on state television, such as from Chinese human rights lawyers and the Hong Kong booksellers.\n",
        "\n",
        "Chinese authorities have so far elected not to place Peng on state television, perhaps aware that her presence -- even only on its English-language platforms -- would run counter to ongoing efforts to censor all discussions around her original allegations, and thus generate more questions within China than answers.\n",
        "Instead, Peng appeared in a 30-minute video call with IOC officials, accompanied by -- and under the close watch of -- a Chinese sports official who formerly served as the Communist Party secretary of the Tennis Administration Center of the General Administration of Sport of China.\n",
        "\n",
        "The interview has not been reported by Chinese state media. But on its website, the IOC posted a statement and a photo of the call. It didn't release the full video, nor explain the circumstances surrounding the virtual meeting, including how it was arranged.\n",
        "And it appears that IOC officials have walked away from the meeting -- at least publicly -- concluding that Peng is OK.\n",
        "\"I was relieved to see that Peng Shuai was doing fine, which was our main concern,\" said Chair of the IOC Athletes' Commission Emma Terho, who joined the video call along with Li Lingwei, the Chinese sports official.\n",
        "By drawing to quick conclusions about Peng's current state and avoiding any mention of her sexual assault allegations that ignited the whole controversy, analysts say the IOC is putting its own credibility on the line -- and potentially risks becoming complicit in Beijing's propaganda push.\n",
        "\"The IOC call hardly alleviates our concerns for Peng's well-being or safety,\" said Wang from the HRW.\n",
        "\"In fact, it begs the question of why the IOC appears to be participating in what is essentially a state-controlled narrative, as only the government and its affiliated media have been allowed to tell Peng's story.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9HL5T_rAz8j"
      },
      "source": [
        "So you have to run k-means algorithm again, and again, then until you find the optimal result, why we it requires initial means, and it matters what you pick for initial means, for example, this centers are initialized like this, these data points.\n",
        "Okay, and actually, using another similar to measure means the these 2D input space.\n",
        "So you can see this input image is broken in two places and each class form or process, actually, similar reasons.\n",
        "But if you don't use equally their distance, instead, you use another way to define a similarity between vectors, you will have different clustering result.\n",
        "So it forms a cluster 1 and this Center is close to these oranges, of course, and these data points, make a cluster 2 and in the same way, we make a cluster 3 and close to 40 K. So, this green point is more close to this data point rather than this data point.\n",
        "But let's say you have different initial means.\n",
        "And then next small step of iteration is change the cluster Center to the average of its assigned, right point.\n",
        "So here is a picture example, each Square corresponds to each object, or data sample, or data point, and you can see the this yellow group are grouped together since they are more similar to each other.\n",
        "Well, you can take another way if we just faced by these data points with two classes.\n",
        "So again, like, in the previous example, If you have this kind of result on this result will not change order.\n",
        "We'll have a better result if this cluster one is formed here because zero is from the here.\n",
        "And the third limitation is the k-means cannot be able to properly cluster in some cases like this.\n",
        "If our algorithm will not stop on this local minimum, you can change this on purpose, enter into here and change this blue blue circle to here.\n",
        "So the initial Center of five classes were here, but we have the new, assigns data point like this wall, like this.\n",
        "This K means clustering but I'm sure this one is quite busy.\n",
        "So we are just going to cross through these data points into K classes and then we iterate, these small steps later.\n",
        "We have only read the data and the final one was refers to learning, but I will talk about it later on in this course.\n",
        "Is the task of grouping, of several of object, or we can say, or set of data samples data points, in a way that the same group are more similar to each other.\n",
        "We will have different clustering results like this and in the previous slide, we said the similar data points are grouped together, but these similar is not a scientific term.\n",
        "And again, let's see the image segmentation result using K means clustering.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDemk0TyypUJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}